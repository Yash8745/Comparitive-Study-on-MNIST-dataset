{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 7s 13ms/step - loss: 0.3947 - accuracy: 0.8827 - val_loss: 0.1329 - val_accuracy: 0.9594\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1234 - accuracy: 0.9627 - val_loss: 0.1025 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0853 - accuracy: 0.9739 - val_loss: 0.0697 - val_accuracy: 0.9775\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0669 - accuracy: 0.9787 - val_loss: 0.0563 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.0516 - val_accuracy: 0.9827\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0482 - accuracy: 0.9849 - val_loss: 0.0585 - val_accuracy: 0.9810\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.0472 - val_accuracy: 0.9851\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.0432 - val_accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0480 - val_accuracy: 0.9847\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0413 - accuracy: 0.9862\n",
      "Test Loss: 0.0413\n",
      "Test Accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape((60000, 28, 28, 1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((10000, 28, 28, 1)).astype('float32') / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Build the LeNet-5 model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 25s 52ms/step - loss: 0.2751 - accuracy: 0.9158 - val_loss: 0.0551 - val_accuracy: 0.9823\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0756 - accuracy: 0.9777 - val_loss: 0.0359 - val_accuracy: 0.9882\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0515 - accuracy: 0.9850 - val_loss: 0.0312 - val_accuracy: 0.9901\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.0258 - val_accuracy: 0.9917\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 0.0223 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0263 - val_accuracy: 0.9921\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0194 - val_accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.0264 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.0219 - val_accuracy: 0.9934\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0213 - val_accuracy: 0.9943\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9943\n",
      "Test Loss: 0.0213\n",
      "Test Accuracy: 0.9943\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "\n",
    "# Build the AlexNet-like model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "with tf.device('/GPU:0'):  # Specify GPU device\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 60s 127ms/step - loss: 0.1415 - accuracy: 0.9554 - val_loss: 0.0478 - val_accuracy: 0.9854\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 0.0241 - val_accuracy: 0.9924\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.0246 - val_accuracy: 0.9919\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 59s 126ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0220 - val_accuracy: 0.9930\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 60s 128ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0208 - val_accuracy: 0.9927\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 60s 128ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0222 - val_accuracy: 0.9926\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 60s 129ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0217 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 60s 128ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0265 - val_accuracy: 0.9923\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0299 - val_accuracy: 0.9911\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0603 - val_accuracy: 0.9862\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0603 - accuracy: 0.9862\n",
      "Test Loss: 0.0603\n",
      "Test Accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "\n",
    "# Build the VGG-like model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "with tf.device('/GPU:0'):  # Specify GPU device\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 195s 415ms/step - loss: 2.2944 - accuracy: 0.1257 - val_loss: 2.2284 - val_accuracy: 0.2588\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 197s 420ms/step - loss: 1.3595 - accuracy: 0.4822 - val_loss: 0.4354 - val_accuracy: 0.8762\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 198s 422ms/step - loss: 0.1976 - accuracy: 0.9444 - val_loss: 0.0990 - val_accuracy: 0.9715\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 199s 425ms/step - loss: 0.0898 - accuracy: 0.9736 - val_loss: 0.0755 - val_accuracy: 0.9799\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 199s 424ms/step - loss: 0.0617 - accuracy: 0.9825 - val_loss: 0.0631 - val_accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 193s 411ms/step - loss: 0.0474 - accuracy: 0.9864 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 217s 464ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.0416 - val_accuracy: 0.9887\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 198s 422ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0418 - val_accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 198s 422ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.0559 - val_accuracy: 0.9855\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 197s 421ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0408 - val_accuracy: 0.9899\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.0408 - accuracy: 0.9899\n",
      "Test loss: 0.0408\n",
      "Test accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Create the ZFNet model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv2D(96, (7, 7), strides=(2, 2), padding='valid', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='valid', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "model.add(layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
